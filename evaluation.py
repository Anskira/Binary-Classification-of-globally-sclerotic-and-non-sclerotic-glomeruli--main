# -*- coding: utf-8 -*-
"""evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZOsDDZ_dasraZ4LSySgk7gtRvKP2spky
"""

import os
import sys
import torch
import torch.nn as nn
import pandas as pd
from PIL import Image
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import matplotlib.pyplot as plt
import cv2
import random
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
import seaborn as sns
from skimage.feature import local_binary_pattern
from skimage.feature import graycomatrix, graycoprops
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import precision_score, recall_score, accuracy_score
import numpy as np
from itertools import chain
import yaml

import yaml

# Load config.yaml
with open("./config.yaml", "r") as file:
    config = yaml.safe_load(file)

excel_path = config['csv_path']
df = pd.read_csv(excel_path)
print(df.head())

#path to both the folders
folder1_path = config['globally_sclerotic_folder']
folder2_path = config['non_globally_sclerotic_folder']
img_paths = [folder1_path, folder2_path]

#adding a new column to the dataframe that contains the path to the image and it's name
df['image_path'] = df['name'].apply(
        lambda x: os.path.join(folder1_path, x) if os.path.exists(os.path.join(folder1_path, x))
        else os.path.join(folder2_path, x) if os.path.exists(os.path.join(folder2_path, x))
        else None
    )

#custom data generator to prepare the image data for batches for feature extraction process, using ImageDataGenerator
def custom_data_generator(df, batch_size, target_size=(224, 224), augment=False):
    datagen = ImageDataGenerator(
        rescale=1.0 / 255,
        horizontal_flip=True if augment else False,
        rotation_range=30 if augment else 0,
        zoom_range=0.2 if augment else 0.0
    )

    while True:
        batch_data = df.sample(n=batch_size)
        images = []
        labels = []

        #iterating throught the batch
        for _, row in batch_data.iterrows():
            img = load_img(row['image_path'], target_size=target_size)
            img_array = img_to_array(img)
            images.append(img_array)
            labels.append(row['ground truth'])

        images = np.array(images)
        labels = np.array(labels)

        # Yield augmented images and their corresponding labels
        yield datagen.flow(images, labels, batch_size=batch_size).__next__()

# Parameters
batch_size = 32
target_size = (224, 224)

train_generator = custom_data_generator(df, batch_size, target_size, augment=True)

# Testing the generator
images, labels = next(train_generator)
print(f"Batch image shape: {images.shape}")  # (batch_size, 224, 224, 3)
print(f"Batch labels: {labels}")

import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# feature extraction functions
def extract_morphological_features(image):
    _, binary_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV)
    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        perimeter = cv2.arcLength(largest_contour, True)
        x, y, w, h = cv2.boundingRect(largest_contour)
        aspect_ratio = float(w) / h
        rect_area = w * h
        extent = float(area) / rect_area
        return [area, perimeter, aspect_ratio, extent]
    else:
        return [0, 0, 0, 0]

def extract_textural_features(image):
    radius = 3
    n_points = 8 * radius

    # Compute LBP (Local Binary Pattern)
    lbp = local_binary_pattern(image.cpu().numpy(), n_points, radius, method='uniform')

    # Compute Haralick features using GLCM (Gray Level Co-occurrence Matrix)
    glcm = graycomatrix(image.cpu().numpy(), distances=[1], angles=[0], levels=256, symmetric=True, normed=True)

    contrast = graycoprops(glcm, 'contrast')[0][0]
    dissimilarity = graycoprops(glcm, 'dissimilarity')[0][0]
    homogeneity = graycoprops(glcm, 'homogeneity')[0][0]
    energy = graycoprops(glcm, 'energy')[0][0]
    correlation = graycoprops(glcm, 'correlation')[0][0]

    return [np.mean(lbp), np.var(lbp), contrast, dissimilarity, homogeneity, energy, correlation]

def process_images_in_batches(csv_path, batch_size=32):
    # Load CSV file
    data_df = pd.read_csv(csv_path)

    data_df['image_path'] = data_df['name'].apply(
        lambda x: os.path.join(folder1_path, x) if os.path.exists(os.path.join(folder1_path, x))
        else os.path.join(folder2_path, x) if os.path.exists(os.path.join(folder2_path, x))
        else None
    )
    # Initialize lists to store features and labels
    features_list = []
    labels_list = []

    # Split data into batches
    num_images = len(data_df)
    for batch_start in range(0, num_images, batch_size):
        batch_end = min(batch_start + batch_size, num_images)
        batch_data = data_df.iloc[batch_start:batch_end]

        print(f"Processing batch {batch_start // batch_size + 1}/{(num_images + batch_size - 1) // batch_size}...")

        for _, row in batch_data.iterrows():
            image_path = row['image_path']  #column contains full paths to images
            label = row['ground truth']  #column contains the class label

            # Read image in grayscale
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

            # Check if the image was loaded successfully
            if image is None:
                print(f"Warning: Unable to load image at {image_path}. Skipping...")
                continue

            # Move image to GPU as a tensor
            image_tensor = torch.tensor(image).to(device)

            # Extract features (morphological and textural)
            morph_features = extract_morphological_features(image)
            textural_features = extract_textural_features(image_tensor)

            # Combine features and append to list
            features_list.append(morph_features + textural_features)
            labels_list.append(label)

        print(f"Batch {batch_start // batch_size + 1} completed.")

    return np.array(features_list), np.array(labels_list)

csv_path = config['csv_path']

# Process images in batches and extract features on GPU
features, labels = process_images_in_batches(csv_path)

# Save extracted features for later use (optional)
# np.save('features.npy', features)
# np.save('labels.npy', labels)

# Split data into train/test sets (optional)
# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

df_array = pd.DataFrame(features, columns=[f'f{i}' for i in range(1,12)])   #converting the features.npy file into a dataframe
df = pd.concat([df, df_array], ignore_index=True,axis=1)                    #concatenating the df_array and df dataframes

print(df.shape)

#renaming the columns for better interpretability
df.rename(columns={0: 'name', 1: 'ground truth',2:'image_path'}, inplace=True)
df.rename(columns={3: 'f1', 4: 'f2',5:'f3',6:'f4',7:'f5',8:'f6',9:'f7',10:'f8',11:'f9',12:'f10',13:'f11'}, inplace=True)

#normalizing some of the columns
scaler = MinMaxScaler()
df[['f1', 'f2','f5','f6','f7']] = scaler.fit_transform(df[['f1', 'f2','f5','f6','f7']])
df.head()

nan_rows = df[df.isna().any(axis=1)]

# Display rows containing NaN values
print(nan_rows)

# Custom Dataset Class
class CustomDataset(Dataset):
    def __init__(self, df, target_size=(224,224), augment=False):
        self.df=df
        self.target_size=target_size

        self.label_counts = self.df['ground truth'].value_counts().to_dict()
        self.label_glomeruli = self.label_counts.get(1, 0)  # Count of 1 instances
        self.label_non_glomeruli = self.label_counts.get(0, 0)

        #transformations
        self.transform=transforms.Compose([
            transforms.Resize(self.target_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229,0.224,0.225])
        ])

        #implementing data augmentation to increase the number of samples
        if augment==False:
            self.augment_transform= transforms.Compose([
                transforms.RandomHorizontalFlip(),
                transforms.RandomRotation(30),
                self.random_zoom(),
                self.transform
            ])

    def random_zoom(self):
        return transforms.RandomAffine(
            degrees=0,           # No rotation
            translate=None,      # No translation
            scale=(0.8, 1.2)     # Random scaling (zoom in or out)
        )

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row=self.df.iloc[idx]

        # Load image
        img_name= row['name']
        img=Image.open(row['image_path'])

        # Convert RGBA to RGB if necessary
        if img.mode=='RGBA':
            img=img.convert('RGB')

        # Apply augmentations if specified
        img=self.augment_transform(img)

        # Extract textual features
        feature_values = row[['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11']].values
        feature_values = np.array(feature_values, dtype=np.float32)

        # Extract label
        label=float(row['ground truth'])

        return img, feature_values, label, self.label_glomeruli, self.label_non_glomeruli, img_name

test_dataset = CustomDataset(df, target_size=(224, 224), augment=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

#loop over DataLoader
for images, features, labels,count_glomeruli, count_non_glomeruli, img_name in test_loader:
    print(f"Batch images shape: {images.shape}")
    print(f"Batch features shape: {features.shape}")
    print(f"Batch labels shape: {labels.shape}")
    print(count_glomeruli.dtype)
    break

#defining the model that will take both the images and features as input, by extending the nn.Module class
class MultiInputModel(nn.Module):
    def __init__(self, image_input_shape, feature_input_shape):
        super(MultiInputModel, self).__init__()

        # Image input branch
        self.image_fc=nn.Sequential(
            nn.Flatten(),
        )

        # Feature input branch
        self.feature_fc=nn.Sequential(
            nn.Linear(feature_input_shape, 64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )

        # Combine both branches
        self.combined_fc=nn.Sequential(
            nn.Linear(224*224*3+64, 64),
            nn.ReLU(),
            nn.Dropout(0.2)
        )

        # Output layer (for binary classification)
        self.output_fc=nn.Sequential(
            nn.Linear(64,2),
            nn.Sigmoid()
        )

    def forward(self, image_input, feature_input):
        x = self.image_fc(image_input)  # Process the image input
        y = self.feature_fc(feature_input)  # Process the feature input

        # Concatenate both branches
        combined = torch.cat((x, y), dim=1)

        # Forward pass through the combined layers
        z = self.combined_fc(combined)

        # Output prediction
        output = self.output_fc(z)

        return output


image_input_shape=(224, 224, 3)

criterion = nn.CrossEntropyLoss()

feature_input_shape=11

model=MultiInputModel(image_input_shape, feature_input_shape)
print(model)

model_path=config['model_path']       #loading the model parameters
model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))
model.eval()

# Test evaluation
import tqdm
def calculate_metrics(y_true, y_pred):
    # Convert probabilities to binary predictions (class 0 or 1)
    y_pred_binary = torch.argmax(y_pred, dim=1).cpu().detach().numpy()  # Get the class with highest probability

    # Convert y_true to numpy
    y_true = y_true.cpu().numpy()

    # Calculate precision and recall
    precision = precision_score(y_true, y_pred_binary)
    recall = recall_score(y_true, y_pred_binary)
    accuracy=accuracy_score(y_true,y_pred_binary)

    return accuracy,precision, recall

test_loss = 0
all_labels = []
all_preds = []
img_names=[]

with torch.no_grad():
    for images, features, labels, count_glomeruli, count_non_glomeruli, img_name in tqdm.tqdm(test_loader, desc="Test Evaluation", leave=False):
        images, features, labels = images.to(device).float(), features.to(device).float(), labels.to(device).long()

        outputs = model(images, features)
        loss = criterion(outputs, labels)
        test_loss += loss.item()

        all_labels.append(labels)
        all_preds.append(outputs)
        img_names.append(img_name)

# Compute test loss and metrics
test_loss /= len(test_loader)
all_labels = torch.cat(all_labels)
all_preds = torch.cat(all_preds)
test_accuracy, test_precision, test_recall = calculate_metrics(all_labels, all_preds)



# Print test results
print(f"Test Loss: {test_loss:.3f}")
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Precision: {test_precision:.4f}")
print(f"Test Recall: {test_recall:.4f}")

binary_preds = torch.argmax(all_preds, dim=1).cpu().numpy()
img_names=list(chain.from_iterable(img_names))

# Create a DataFrame for the CSV file
results_df = pd.DataFrame({
    'Image Name': img_names,
    'Prediction': binary_preds
})

# Save the DataFrame to a CSV file
results_df.to_csv("evaluation.csv", index=False)



